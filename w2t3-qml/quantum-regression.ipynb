{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Quantum Regression to fit Parton Density Functions\n",
    "\n",
    "## 1. From classical ML to quantum ML\n",
    "\n",
    "> In the following we refer to supervised machine learning theory.\n",
    "\n",
    "When dealing with a ML problem we typically need:\n",
    "1. A parameteric model $\\mathcal{M}$;\n",
    "2. A way to embed input data $x$ into $\\mathcal{M}$;\n",
    "3. A predictor for estimating the output $y$;\n",
    "4. A loss function $J$;\n",
    "5. An optimizer $\\mathcal{O}$.\n",
    "\n",
    "In the following problem we are going to use Quantum Computing tools as interpeters\n",
    "of the previous bullet points, building a Quantum Machine Learning (QML) [1-3] algorithm. \n",
    "\n",
    "<img src=\"figures/qml.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "\n",
    "In particular:\n",
    "1. we use a variational quantum circuit $C$ as $\\mathcal{M}$;\n",
    "2. we encode data into the circuit setting them as rotational angles in $RY$ and \n",
    "   $RZ$ gates following the procedure purposed in [4];\n",
    "3. we use the expected value of a target Z observable as predictor: $$ y_{\\rm est} = \\langle 0 | C(x|\\vec{\\theta})^{\\dagger} Z C(x|\\vec{\\theta}) | 0 \\rangle. $$ \n",
    "4. we use a Mean-Squared Error (MSE) loss function, since we tackle a supervised ML\n",
    "   problem: $$J_{\\rm mse} = \\frac{1}{N_{\\rm data}} \\sum_j \\bigl[ y_{j,\\rm meas} - y_{j, \\rm est} \\bigr]^2.$$\n",
    "5. we build an Adam descent using the parameter shift rule [5-7].\n",
    "\n",
    "#### Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload a module after modifications without restarting kernel\n",
    "from importlib import reload\n",
    "# to clear cell's output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# our version of a quantum regressor\n",
    "import qpdf_scripts.vqregressor as vqr\n",
    "from qibo import set_backend\n",
    "\n",
    "set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A look to the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to tackle two different targets:\n",
    "1. a dummy trigonometric functions to see how the vqr works;\n",
    "2. one of the eight flavours of the proton PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target(x, y, label, xscale=\"linear\"):\n",
    "    \"\"\"Plot target function to be fitted\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.title(label)\n",
    "    plt.plot(x, y, color=\"purple\", alpha=0.7, lw=2)\n",
    "    plt.plot(x, y, color=\"purple\", alpha=0.4, marker='.', markersize=12, ls='')\n",
    "    plt.xlabel(\"y\")\n",
    "    plt.ylabel(\"x\")\n",
    "    plt.xscale(xscale)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dummy trigonometric function\n",
    "\n",
    "The first target is the following trigonometric function:\n",
    "$$ y = 2x + \\sin(8x) - \\cos(3x)^2, $$\n",
    "then normalised to have $[0,1]$ as co-domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigonometric target\n",
    "trig_target_x = np.linspace(0,1,100)\n",
    "trig_target_y = 2*trig_target_x * np.sin(8*trig_target_x) - np.cos(3*trig_target_x)**2\n",
    "# we use a <Z> as predictor, which is defined in [-1,1]\n",
    "# for simplicity we use the range [0,1]\n",
    "trig_target_y = (trig_target_y - np.min(trig_target_y)) / (np.max(trig_target_y)- np.min(trig_target_y))\n",
    "plot_target(trig_target_x, trig_target_y, label=\"Trigonometric dummy function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 $u$ quark PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEP target\n",
    "flav = 11\n",
    "hep_data = np.loadtxt(\"data/qpdf_data/8flavours.dat\")\n",
    "hep_x = hep_data.T[0]\n",
    "hep_y = hep_data.T[flav]\n",
    "plot_target(hep_x, hep_y, label=\"PDF flavour\", xscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training of the VQR to fit the trigonometric function\n",
    "\n",
    "A Variational Quantum Regressor can be found in `qpdf_scripts/vqregressor.py`. Before using it, we have a look to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the regressor\n",
    "regressor = vqr.VQRegressor(data=trig_target_x, labels=trig_target_y, layers=3, nqubits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show initial - not trained - predictions\n",
    "regressor.show_predictions(\"Before training\", xscale=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the training\n",
    "history = regressor.gradient_descent(\n",
    "    learning_rate=0.1,\n",
    "    epochs=250,\n",
    "    live_plotting=True\n",
    ")\n",
    "\n",
    "# clear output after the execution\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.show_predictions(\"After training\", xscale=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look to the loss function history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Loss function history\")\n",
    "plt.plot(history, lw=2, color='purple', alpha=0.7)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r\"$J$\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercise: fitting a PDF\n",
    "The second target is a proton PDF. In order to fit it, we are going to follow \n",
    "the ansatz introduced in [8].\n",
    "Modify the ansatz of `vqregressor.VQRegressor` in order to follow the one presented \n",
    "in Ref. [8], thus perform a regression using the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the VQR module after your modifications\n",
    "reload(vqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = vqr.VQRegressor(data=hep_x, labels=hep_y, layers=5, nqubits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.show_predictions(\"Before training\", xscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regressor.gradient_descent(\n",
    "    learning_rate=0.15,\n",
    "    epochs=250,\n",
    "    live_plotting=True\n",
    ")\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.show_predictions(\"After training\", xscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] [_An introduction to quantum machine learning_, 2014](https://arxiv.org/abs/1409.3097)\n",
    "\n",
    "[2] [_Quantum Machine Learning_, 2016](https://arxiv.org/abs/1611.09347)\n",
    "\n",
    "[3] [_Quantum Algorithm for Linear Regression_, 2014](https://arxiv.org/abs/1402.0660)\n",
    "\n",
    "[4] [_Data re-uploading for a universal quantum classifier_, 2020](https://arxiv.org/abs/1907.02085)\n",
    "\n",
    "[5] [_Stochastic gradient descent for hybrid quantum-classical optimization_, 2021](https://arxiv.org/abs/1910.01155)\n",
    "\n",
    "[6] [_Adam: A Method for Stochastic Optimization_, 2014](https://arxiv.org/abs/1412.6980)\n",
    "\n",
    "[7] [_A quantum analytical Adam descent through parameter shift rule using Qibo_, 2022](https://arxiv.org/abs/2210.10787)\n",
    "\n",
    "[8] [_Determining the proton content with a quantum computer_, 2021](https://arxiv.org/abs/2011.13934)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
