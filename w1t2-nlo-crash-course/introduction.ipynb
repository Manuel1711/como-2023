{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd470f8",
   "metadata": {},
   "source": [
    "# Second tutorial of the first week of the AAIPHEP Como school\n",
    "\n",
    "- Welcome!\n",
    "- Tutors: Felix Hekhorn and Tanjona Rabemananjara and Christopher Schwan\n",
    "- Idea of this tutorial: accompanying tutorial to Jennifer's QCD lectures\n",
    "- Plan for today:\n",
    "  - Answer: how do you calculate theory predictions: (total/differential) cross sections, structure functions\n",
    "  - Less focus on *why* and more focus on *how*\n",
    "  - Questions, anything unclear? Please interupt us!\n",
    "  - We will talk a lot, but ideally we talk to each other\n",
    "  - For the exercises: if you'd like team up, please do! If you want to solve everything yourself that's also fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ee109",
   "metadata": {},
   "source": [
    "# What do we need theory predictions for?\n",
    "\n",
    "- We usually want to answer two types of questions:\n",
    "  1. How good is the standard model? To answer this question, we must compare theory predictions with experimental measurements;\n",
    "  2. If we trust data and theory, we often want to extract quantities that are hard/impossible to calculate! For instance, parton distribution functions (PDFs), see picture below.\n",
    "  \n",
    "![fitting PDFs](figures/Fit.png)\n",
    "\n",
    "- here: theory, other tutorials discuss methodology aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334313fc",
   "metadata": {},
   "source": [
    "# How do we calculate a prediction?\n",
    "\n",
    "- there's a 'recipe' that we will present\n",
    "- very complicated to spell out in full detail and generality: if interested attend QFT lectures!\n",
    "- here: bird's eye view, overview. Introduce and understand terminology so you can talk to theorists!\n",
    "- two important ingredients:\n",
    "  1. factorization (should be covered in Jenny's lectures) and\n",
    "  2. perturbation theory (you should know this from quantum mechanics)\n",
    "\n",
    "## 1. Factorization\n",
    "\n",
    "- Many colliders use bound states: protons (LHC), anti-protons (Tevatron), or heavier nuclei like lead (LHC)\n",
    "- Bound states are very difficult objects, but if we scatter them off-each other or if we probe them using leptons we usually assume that short-distance dynamics (scattering process) *factorizes* from long-distance dynamics (interaction in the hadron)\n",
    "- This assumption can be proven in few cases\n",
    "- Essentially we're assuming that in the very short moment when the scattering happens the bound states consists of a bunch of non-interacting particles: we call these *partons*\n",
    "- Partons are the 'parts' of the hadron, and the sum of all partons are the hadron\n",
    "- In terms of the standard model the partons are elementary particles (quarks $\\mathrm{q}$, gluons $\\mathrm{g}$, but also photons $\\gamma$, leptons $\\ell$ and so on), and we can easily calculate with them\n",
    "\n",
    "### Parton distribution functions (PDFs)\n",
    "\n",
    "- Rough idea: we can't directly/easily calculate *hadronic* cross sections (hadrons are bound states), but we can calculate *partonic* cross sections\n",
    "- PDFs $f_a^h (x)$ for a hadron $h$ 'translate' between these to pictures\n",
    "- $f_a^h (x)$ is the 'probability' of finding a parton $a$ in the hadron $h$ with momentum fraction $x \\in [0, 1]$\n",
    "- for one hadron (for instance HERA):\n",
    "  $$ \\left\\langle \\frac{\\sigma^{h \\ell \\to F}}{\\mathrm{d} \\mathcal{O}} \\right\\rangle = \\sum_{a} \\int_0^1 \\mathrm{d} z f_a^h (z) \\frac{\\sigma_{ab \\to F} (z)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- for two hadrons (for instance LHC):\n",
    "  $$ \\left\\langle \\frac{\\sigma^{hh \\to F}}{\\mathrm{d} \\mathcal{O}} \\right\\rangle = \\sum_{a,b} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^h (x_1) f_b^h (x_2) \\frac{\\sigma_{ab \\to F} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- PDFs describe the long-distance dynamics, the partonic cross sections the short-distance dynamics\n",
    "- these are our 'master formulae':\n",
    "  1. We can calculate the hadronic cross sections $\\sigma_{ab \\to F} (x_1, x_2)/\\mathrm{d} \\mathcal{O}$ using the previously determined PDFs\n",
    "  2. or we use predictions and the corresponding measurements to fit PDFs\n",
    "\n",
    "### Caveats\n",
    "\n",
    "- PDFs aren't probability distributions in that sense that\n",
    "  $$ \\int_0^1 \\mathrm{d} x f_a (x) \\neq 1 $$\n",
    "  and usually the integral isn't convergent: we can find infinitely many partons in the proton\n",
    "- but the electric charge and the momentum of the hadron is conserved: sum rules\n",
    "\n",
    "## 2. Perturbation theory: calculating a partonic cross section\n",
    "\n",
    "- Standard model Lagrangian $\\mathcal{L}_\\text{SM}$, solve the equations of motion, just like in classical mechanics\n",
    "- Well, not quite: EOMs are coupled, non-linear differential equations\n",
    "- A good tool is perturbation theory: divide Lagrangian into free fields + perturbation; alternative: lattice QCD\n",
    "- In the SM we have the running couplings $\\alpha_s (M_\\mathrm{Z}^2) = 0.118$ and $\\alpha(0) \\approx 1/137 \\approx 0.0073$\n",
    "- expand in those two couplings:\n",
    "  $$ \\frac{\\sigma_{ab} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} = \\sum_{n,m} \\alpha_\\mathrm{s}^n \\alpha^m \\frac{\\sigma_{ab}^{n,m} (x_1, x_2)}{\\mathrm{d} \\mathcal{O}} $$\n",
    "- since $\\alpha_s \\gg \\alpha$ we usually look only at the lowest order $m$ and calculate corrections in $n$: QCD corrections\n",
    "- this isn't always reliable, sometimes electroweak (EW) corrections are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb98a8c-77ee-4784-bfa8-2f5716edd8b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The recipe for leading-order (LO) calculations\n",
    "\n",
    "Here we'd like to calculate the cross section of the production of a same-flavour opposite-sign (SFOS) lepton-pair, for instance muons, at the LHC: $\\mathrm{p}\\mathrm{p} \\to \\ell\\bar{\\ell}$. This is often called Drell-Yan lepton pair production.\n",
    "\n",
    "## 1. Write down observable definition and master formula\n",
    "\n",
    "We use the master formula for two incoming protons:\n",
    "\n",
    "$$ \\sigma^{\\mathrm{p}\\mathrm{p} \\to F} = \\sum_{a,b} \\int \\mathrm{d} x_1 \\mathrm{d} x_2 f_a^\\mathrm{p} (x_1) f_b^\\mathrm{p} (x_2) \\sigma_{ab \\to \\ell\\bar{\\ell}} (x_1, x_2) $$\n",
    "\n",
    "For simplicity we restrict ourselves to the photon-photon contribution, so $a, b = \\gamma$. We assume that PDFs are given.\n",
    "\n",
    "## 2. Draw all Feynman diagrams\n",
    "\n",
    "You need to identify all relevant input states and all valid output states, connect them in all possible ways using the allowed vertices and propagators and assign four-momenta to them.\n",
    "\n",
    "In our example of photon-photon scattering to SFOS lepton-pair there are two diagrams: one with a $t$-channel propagator and one with a $u$ propagator:\n",
    "| t | u | \n",
    "| :-: | :-: |\n",
    "| <img src=\"figures/lo-t.png\" width=260 height=260 /> | <img src=\"figures/lo-u.png\" width=260 height=260 /> |\n",
    "\n",
    "$$ \\mathrm{i} \\mathcal M_t = \\bar u(p_2) \\mathrm{i} e \\gamma_\\mu \\frac{\\mathrm{i} ( \\cancel p_2 - \\cancel k_2)}{t} \\mathrm{i} e \\gamma_\\nu u(p_2) \\epsilon^\\nu (k_1) \\epsilon^\\mu (k_2) \\quad \\mathrm{i} \\mathcal{M}_u = \\bar u(p_2) \\mathrm{i} e \\gamma_\\mu \\frac{\\mathrm{i} (\\cancel p_2 - \\cancel k_1)}{u} \\mathrm{i} e \\gamma_\\nu u(p_2) \\epsilon^\\nu (k_1) \\epsilon^\\mu (k_2) $$\n",
    "\n",
    "## 3. Compute matrix elements\n",
    "\n",
    "Sum all amplitudes and take the modulus squared. It is common practice to also account for the flux factor and the spin and color sums together with their eventual average. Recall to average on the input and to sum on the output.\n",
    "\n",
    "In our example we find:\n",
    "$$ \\frac {1}{2 s} |\\mathcal M_t + \\mathcal M_u |^2 = \\frac{\\alpha_{em}^2}{2s} \\left(\\frac t u + \\frac u t\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc0bf80-787e-427c-aec4-f835309eaf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photon_photon_matrix_element(s: float, t: float, u: float) -> float:\n",
    "    alpha0 = 1.0 / 137.03599911\n",
    "    return alpha0 * alpha0 / 2.0 / s * (t / u + u / t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42252059-033f-45ee-b431-e48c094b514b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Determine phase space decomposition\n",
    "\n",
    "We need to integrate the squared matrix elements over all possible momenta, that is all momenta which fulfill momentum conservation and which are on-shell: $ p_i^2 = m_i^2 $. This integral (Lorentz invariant phase-space (LIPS)) is:\n",
    "\n",
    "$$ \\int \\mathrm{d} \\mathrm{LIPS} = \\int \\left( \\prod_{i=1}^n \\mathrm{d}^4 p_i \\right) \\, \\delta^{(4)} \\left( k_1 + k_2 - \\sum_{i=1}^n p_i \\right) \\prod_{i = 1}^n \\delta \\left( p_i^2 - m_i^2 \\right) $$\n",
    "\n",
    "and has $4n$ integration dimensions, reduced to $3n - 4$ through the momentum conservation ($-4$) and on-shell conditions ($-n$).\n",
    "\n",
    "In our example we have two final state particles ($n = 2$), so effectively we integrate over $3n - 4 = 2$ dimensions. We choose to integrate over these two variables:\n",
    "1. $\\cos \\theta$, where $\\theta$ measures the angle of one of the leptons w.r.t. the beam axis and\n",
    "2. the angle $\\phi$, which is another angle transverse to the beam axis.\n",
    "\n",
    "Matrix elements do not depend on the angle $\\phi$, since the collision is symmetric around the beam axis.\n",
    "\n",
    "## 5. Compute phase space integrals\n",
    "\n",
    "We also need to generate the parton fractions, that is the arguments $x_1$ and $x_2$ of the two PDFs. We do this by rewriting the integral into $\\tau$, relative centre-of-mass energy squared and $y$, the rapidity relating the hadronic and partonic centre-of-mass frames:\n",
    "\n",
    "$$ \\int_0^1 \\mathrm{d} x_1 \\int_0^1 \\mathrm{d} x_2 = \\int \\mathrm{d} \\tau \\int \\mathrm{d} y $$\n",
    "\n",
    "This transformation is chosen such that the jacobian contains a flux factor, cancelling the flux factor multiplied to the qured matrix elements above.\n",
    "\n",
    "We approximate the integrals numerically by using a Monte Carlo integration, which computes the average of the integrand evaluated using uniformly chosen random numbers $r_1, r_2, r_3$:\n",
    "\n",
    "$$ \\int_0^1 \\mathrm{d} r_1 \\int_0^1 \\mathrm{d} r_2 \\int_0^1 \\mathrm{d} r_3 f(r_1, r_2, r_3) \\approx \\frac{1}{N} \\sum_{i=1}^N f(r_1^i, r_2^i, r_3^i) $$\n",
    "\n",
    "Translated to Python code this reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357d81ff-5c6b-4514-82f7-e5575b80215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def hadronic_ps_gen(\n",
    "    mmin: float, mmax: float\n",
    ") -> Tuple[float, float, float, float, float, float]:\n",
    "    r\"\"\"Hadronic phase space generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mmin :\n",
    "        minimal energy :math:`\\sqrt{s_{min}}`\n",
    "    mmax :\n",
    "        maximal energy :math:`\\sqrt{s_{max}}`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s :\n",
    "        Mandelstam s\n",
    "    t :\n",
    "        Mandelstam t\n",
    "    u :\n",
    "        Mandelstam u\n",
    "    x1 :\n",
    "        first momentum fraction\n",
    "    x2 :\n",
    "        second momentum fraction\n",
    "    jacobian :\n",
    "        jacobian from the uniform generation\n",
    "\n",
    "    \"\"\"\n",
    "    smin = mmin * mmin\n",
    "    smax = mmax * mmax\n",
    "\n",
    "    r1 = np.random.uniform()\n",
    "    r2 = np.random.uniform()\n",
    "    r3 = np.random.uniform()\n",
    "    \n",
    "    # generate partonic x1 and x2\n",
    "    tau0 = smin / smax\n",
    "    tau = pow(tau0, r1)\n",
    "    y = pow(tau, 1.0 - r2)\n",
    "    x1 = y\n",
    "    x2 = tau / y\n",
    "    s = tau * smax\n",
    "\n",
    "    jacobian = tau * np.log(tau0) * np.log(tau0) * r1\n",
    "\n",
    "    # theta integration (in the CMS)\n",
    "    cos_theta = 2.0 * r3 - 1.0\n",
    "    jacobian *= 2.0\n",
    "\n",
    "    # reconstruct invariants (in the CMS)\n",
    "    t = -0.5 * s * (1.0 - cos_theta)\n",
    "    u = -0.5 * s * (1.0 + cos_theta)\n",
    "\n",
    "    # phi integration\n",
    "    jacobian *= 2.0 * np.math.acos(-1.0)\n",
    "\n",
    "    return [s, t, u, x1, x2, jacobian]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f003f3",
   "metadata": {},
   "source": [
    "Now we can test the integration by generating a phase-space point between $s_\\text{min} = 10~\\text{GeV}^2$ and $s_\\text{max} = 7000~\\text{GeV}^2$ (our hadronic beam energy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f1be2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44195.58876606601, -23939.92017502279, -20255.668591043217, 0.006467336353391884, 0.139462483758273, 1.041148158684121]\n",
      "s + t + u = 0.0\n"
     ]
    }
   ],
   "source": [
    "tuple = hadronic_ps_gen(10.0, 7000.0)\n",
    "print(tuple)\n",
    "print(\"s + t + u =\", tuple[0] + tuple[1] + tuple[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a135784-1ce2-49f2-8c21-b1447c8eb83a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Join phase space integration and matrix elements\n",
    "\n",
    "Finally, we have to\n",
    "- put everything together,\n",
    "- transform the phase-space variables into the well-known LAB quantities, and\n",
    "- add phase-space cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bb89769-55ad-43b8-8844-41538ae2e9a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pineappl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpineappl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_grid\u001b[39m(grid: pineappl\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39mGrid, calls: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fill grid with points.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pineappl'"
     ]
    }
   ],
   "source": [
    "import pineappl\n",
    "\n",
    "def fill_grid(grid: pineappl.grid.Grid, calls: int):\n",
    "    \"\"\"Fill grid with points.\"\"\"\n",
    "\n",
    "    # in GeV^2 pbarn\n",
    "    hbarc2 = 389379372.1\n",
    "\n",
    "    for _ in range(calls):\n",
    "        # compute phase space\n",
    "        s, t, u, x1, x2, jacobian = hadronic_ps_gen(10.0, 7000.0)\n",
    "        # build observables\n",
    "        ptl = np.sqrt((t * u / s))\n",
    "        mll = np.sqrt(s)\n",
    "        yll = 0.5 * np.log(x1 / x2)\n",
    "        ylp = np.abs(yll + np.math.acosh(0.5 * mll / ptl))\n",
    "        ylm = np.abs(yll - np.math.acosh(0.5 * mll / ptl))\n",
    "\n",
    "        jacobian *= hbarc2 / calls\n",
    "\n",
    "        # cuts for LO for the invariant-mass slice containing the\n",
    "        # Z-peak from CMSDY2D11\n",
    "        if (\n",
    "            ptl < 14.0\n",
    "            or np.abs(yll) > 2.4\n",
    "            or ylp > 2.4\n",
    "            or ylm > 2.4\n",
    "            or mll < 60.0\n",
    "            or mll > 120.0\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # build event\n",
    "        weight = jacobian * photon_photon_matrix_element(s, u, t)\n",
    "        q2 = 90.0 * 90.0\n",
    "    \n",
    "        # put\n",
    "        grid.fill(x1, x2, q2, 0, np.abs(yll), 0, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26191d31-ea97-4b57-880c-2a20713cff6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pineappl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting PineAPPL grid to disk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     grid\u001b[38;5;241m.\u001b[39mwrite(filename)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDY-AA.pineappl.lz4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(calls, filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate the grid.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create a new luminosity function for the $\\gamma\\gamma$ initial state\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m lumi_entries \u001b[38;5;241m=\u001b[39m [\u001b[43mpineappl\u001b[49m\u001b[38;5;241m.\u001b[39mlumi\u001b[38;5;241m.\u001b[39mLumiEntry([(\u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)])]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# only LO $\\alpha_\\mathrm{s}^0 \\alpha^2 \\log^0(\\xi_\\mathrm{R}) \\log^0(\\xi_\\mathrm{F})$\u001b[39;00m\n\u001b[1;32m      6\u001b[0m orders \u001b[38;5;241m=\u001b[39m [pineappl\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39mOrder(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pineappl' is not defined"
     ]
    }
   ],
   "source": [
    "def main(calls: int, filename: str):\n",
    "    \"\"\"Generate the grid.\"\"\"\n",
    "    # create a new luminosity function for the $\\gamma\\gamma$ initial state\n",
    "    lumi_entries = [pineappl.lumi.LumiEntry([(22, 22, 1.0)])]\n",
    "    # only LO $\\alpha_\\mathrm{s}^0 \\alpha^2 \\log^0(\\xi_\\mathrm{R}) \\log^0(\\xi_\\mathrm{F})$\n",
    "    orders = [pineappl.grid.Order(0, 2, 0, 0)]\n",
    "    bins = np.arange(0, 2.4, 0.1)\n",
    "    params = pineappl.subgrid.SubgridParams()\n",
    "    grid = pineappl.grid.Grid.create(lumi_entries, orders, bins, params)\n",
    "\n",
    "    # fill the grid with phase-space points\n",
    "    print(f\"Generating {calls} events, please wait...\")\n",
    "    fill_grid(grid, calls)\n",
    "    print(f\"Writing PineAPPL grid to disk: {filename}\")\n",
    "    grid.write(filename)\n",
    "\n",
    "\n",
    "main(100, \"DY-AA.pineappl.lz4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a00830-e1a5-4c5f-9c93-983c04090e6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Computing higher-order matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e252bf-e94d-478a-bb3e-4de1d4000e0d",
   "metadata": {},
   "source": [
    "Our considerations so far are dealing with an leading-order calculation - what changes if we go to higher perturbative orders? In order to investigate this let's consider a simpler example than Drell-Yan: the computation of DIS structure functions. Although this calculation is conceptionally much simpler it turns out that higher-order corrections bring a whole new level of complications at any level of our algorithm. We will thus refrain from giving all details, but instead try to convey the most relevant ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dd1f6-883c-4030-b474-3379d22e6c9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Draw all Feynman diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd3531-284e-40f4-ac0e-09ec3dba5c97",
   "metadata": {},
   "source": [
    "At LO DIS there is a single diagram:\n",
    "\n",
    "| LO |  \n",
    "| :-: | \n",
    "| <img src=\"figures/lo-light.png\" width=200 height=200 /> |\n",
    "\n",
    "Starting at next-to-leading order (NLO) we need to consider three genuinely new types of diagrams: virtual corrections, real emissions and new partonic channels. Let's discuss them in turn, next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d304b78-4bf6-4ea4-ae91-a80b24e94c8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Virtual corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618b595-e6b7-4d4e-8c4a-30e215e6e180",
   "metadata": {},
   "source": [
    "- one can add loops inside diagrams\n",
    "- the loop momentum can be whatever and thus needs to be integrated\n",
    "- calculating loops is an industry on it's own\n",
    "- the difficulty raises with the number of loops and participating masses\n",
    "- there is a lot of math involved here: Group theory, algebras, function theory, special functions, complex analysis (what ever)\n",
    "- for DIS there is 1 virtual diagram: people refer to this as triangle\n",
    "- the triangle is one of the simplest loop intragrals and it is given by http://qcdloop.web.cern.ch/qcdloop/\n",
    "- they contain soft poles, in the example here: this corresponds to this propagator here\n",
    "- you need to find a way to deal with this pole -> in DR it manifests as $1/\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409597c-21ed-4277-a976-d795522d3b81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Real emission of gluons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d3a39-6242-422f-a22f-96b79bcccb3a",
   "metadata": {},
   "source": [
    "- gluons can be emitted of any quark line in any point in the diagram\n",
    "- in DIS there are two diagrams\n",
    "- radiated gluons generate soft and/or collinear poles and they can even overlap\n",
    "- for DIS this corresponds to this propagator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f955b6-69ae-4966-94a7-ad51da5bd451",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### New partonic channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbabe4-13e3-49c9-8548-e98ac8958396",
   "metadata": {},
   "source": [
    "- you need to consider also the case of new initial state partons\n",
    "- in DIS at NLO there is a new channel opening: gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ed314-58ad-4114-96b7-33fcd7b2f4f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Coming back to the bigger picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403e0fc-b3a1-430e-8c77-a189aec0dd46",
   "metadata": {},
   "source": [
    "- the number of diagrams grows typically with factorial\n",
    "- sooner or later you need an automatic program to do the job for you: e.g. qgraf or FeynArts\n",
    "- actually \"drawing\" is not really neede as long as you have a way to iterate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bab272-27ec-4193-87d1-0d27473fc56f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Compute all matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6aebf-4569-4cef-b99c-43698bf80c4f",
   "metadata": {},
   "source": [
    "- one has to square the sum of all Feynman diagrams (recall they grow factorial)\n",
    "- this results in a list of Dirac traces\n",
    "- one can solve those analytically (using Dirac algebra), but this is only possible for a small number of matrix elements\n",
    "- else one has to find a numerical implementation, typically relying on some explicit representation of the spinors and their associated helicities\n",
    "- the soft and collinear structure of matrix elements can be predicted (and checked) a priori\n",
    "- for the case of NLO DIS we get solve the traces by hand and get these matrix elements: see `notes27-dis-nlo.pdf`\n",
    "- Note the appearence of color factors, pis, Gamma functions, poles in epsilon, scale^epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c10c1-6e10-4315-acbc-997e0a2d8eda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Determine phase space decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f2630-a2a9-49a4-be61-7c535a4d7be4",
   "metadata": {},
   "source": [
    "- find the maximum number of phase space constraints\n",
    "- find a suitable representation for all parton momenta\n",
    "- phase space integrals regularly involve the [Källén function](https://en.wikipedia.org/wiki/K%C3%A4ll%C3%A9n_function) and d-dimensional spheres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd098-6a9f-4776-baff-921a4c97c284",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Compute phase space integrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4848eb-5bb8-4fea-8587-27d0c135740d",
   "metadata": {},
   "source": [
    "- computing phase space integrals has a (close) connection to loop integrals\n",
    "- phase space integrals can be computed numerically using Monte Carlo techniques (as in our example), but at higher order the kinematics is getting more involved\n",
    "- for the case of NLO DIS we need the 2-to-2 particle phase space which we can write as: see `notes27-ps.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf51e8-5e54-4c87-b605-fd2c04c0a5a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Join phase space and matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec70aac-c3dd-4edd-b651-70959fd83568",
   "metadata": {},
   "source": [
    "- this requires an siginifcant amount of book keeping\n",
    "- soft + virtual have to cancel against each other\n",
    "- observable definitions have to be infrared safe\n",
    "- collinear poles have to cancel with the proper PDF definition\n",
    "- remember cuts and observable definitions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
